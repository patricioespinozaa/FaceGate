{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znFKmZ-I8ACk"
   },
   "source": [
    "Modelo Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuV2SUaVB5U4"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_array(img_array):\n",
    "    img = img_array.resize((224, 224)).convert('RGB') #cambia dim de imagen para coincidir con el modelo (pasamos a rgb tmb porsiaca)\n",
    "    img = np.array(img).astype('float32') #cambiar estructura para mandar al modelo correctamente\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img, version=2)\n",
    "    return img\n",
    "\n",
    "def get_embedding_from_array(model, img_array):\n",
    "    img = preprocess_image_from_array(img_array) #llama al modelo con la imagen preprocesada para obtener la vectorizacion de los features faciales\n",
    "    embedding = model.predict(img)\n",
    "    return embedding[0]\n",
    "\n",
    "def verify(embedding1, embedding2, threshold=0.5): #ve distancia coseno lol\n",
    "    dist = cosine(embedding1, embedding2)\n",
    "    print(f\"Distancia coseno: {dist}\")\n",
    "    return dist < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgeMDx1eCFKr"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg') #modelo sin capa de softmax para hacer 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB8cb6NlCHxn"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "#subir las 2 imagenes a comparar\n",
    "\n",
    "imgs = list(uploaded.keys())\n",
    "img1 = Image.open(BytesIO(uploaded[imgs[0]]))\n",
    "img2 = Image.open(BytesIO(uploaded[imgs[1]]))\n",
    "\n",
    "# Extraer embeddings\n",
    "emb1 = get_embedding_from_array(model, img1)\n",
    "emb2 = get_embedding_from_array(model, img2)\n",
    "\n",
    "# Verificar\n",
    "if verify(emb1, emb2):\n",
    "    print(\"✅ Coincidencia: acceso autorizado\")\n",
    "else:\n",
    "    print(\"❌ No coincide: acceso denegado\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
